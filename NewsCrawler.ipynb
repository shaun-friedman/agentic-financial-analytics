{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d737d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from pprint import pprint\n",
    "from transformers import pipeline, SummarizationPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c333c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yfinance_aticle_crawler(news_obj: dict) -> dict[str, str]:\n",
    "    \"\"\"\n",
    "    Fetch the full article HTML response from a Yahoo Finance news object.\n",
    "\n",
    "    The function extracts the article URL from the provided `news_obj` dictionary,\n",
    "    constructs a session with appropriate headers to mimic a browser, and retrieves\n",
    "    the article content. It returns a dictionary containing the article's title,\n",
    "    URL, and raw HTML text.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    news_obj : dict\n",
    "        A Yahoo Finance news dictionary containing article metadata with either \n",
    "        \"clickThroughUrl\" or \"previewUrl\" under `news_obj[\"content\"]`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict[str, str]\n",
    "        A dictionary with the keys:\n",
    "        - \"title\": The article title.\n",
    "        - \"url\": The resolved article URL.\n",
    "        - \"response_text\": The raw HTML text of the article.\n",
    "    \"\"\"\n",
    "    if news_obj[\"content\"][\"clickThroughUrl\"] is not None:\n",
    "        url = news_obj[\"content\"][\"clickThroughUrl\"][\"url\"]\n",
    "    else:\n",
    "        url = news_obj[\"content\"][\"previewUrl\"]\n",
    "\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:128.0) Gecko/20100101 Firefox/128.0\",\n",
    "        \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\",\n",
    "        \"Accept-Language\": \"en-US,en;q=0.5\",\n",
    "        \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "        \"Referer\": \"https://www.google.com/\",\n",
    "        \"Connection\": \"keep-alive\",\n",
    "        \"Upgrade-Insecure-Requests\": \"1\",\n",
    "        \"DNT\": \"1\",  # Do Not Track\n",
    "    }\n",
    "\n",
    "    session = requests.Session()\n",
    "    response = session.get(url, headers=headers)\n",
    "    session.close()\n",
    "\n",
    "    return {\n",
    "        \"title\": news_obj[\"content\"][\"title\"],\n",
    "        \"url\": url,\n",
    "        \"response_text\": response.text\n",
    "    }\n",
    "\n",
    "\n",
    "def yfinance_article_cleaner(response_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Clean and extract the main text from a Yahoo Finance article HTML string.\n",
    "\n",
    "    This function removes irrelevant parts of the article such as navigation text,\n",
    "    \"Related articles,\" \"Read more,\" and other footer or promotional content.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    response_text : str\n",
    "        The raw HTML of the article.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        The cleaned article text with unnecessary sections removed.\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(response_text, \"html.parser\")\n",
    "    plain_text = soup.get_text(separator=\" \", strip=True)\n",
    "\n",
    "    pattern_leader = \"^.*In this article:\"\n",
    "    relevant_text = re.sub(pattern=pattern_leader, repl=\"\", string=plain_text)\n",
    "\n",
    "    for marker in [\"Related articles\",\n",
    "                   \"Read more\",\n",
    "                   \"Continue Reading\",\n",
    "                   \"Story Continues\",\n",
    "                   \"View Comments\"]:\n",
    "        idx = relevant_text.rfind(marker)\n",
    "        if idx != -1:\n",
    "            relevant_text = relevant_text[:idx]\n",
    "\n",
    "    return relevant_text.strip()\n",
    "\n",
    "\n",
    "def yfinance_pull_clean(news_obj: dict) -> dict[str, str]:\n",
    "    \"\"\"\n",
    "    Fetch and clean a Yahoo Finance news article.\n",
    "\n",
    "    This function serves as a pipeline: it retrieves the raw article HTML\n",
    "    using `yfinance_aticle_crawler` and then cleans the text with\n",
    "    `yfinance_article_cleaner`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    news_obj : dict\n",
    "        A Yahoo Finance news dictionary containing article metadata.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict[str, str]\n",
    "        A dictionary containing:\n",
    "        - \"title\": Article title\n",
    "        - \"url\": Article URL\n",
    "        - \"response_text\": Raw HTML\n",
    "        - \"clean_text\": Cleaned article body text\n",
    "    \"\"\"\n",
    "    response_obj = yfinance_aticle_crawler(news_obj)\n",
    "    response_obj[\"clean_text\"] = yfinance_article_cleaner(\n",
    "        response_obj[\"response_text\"]\n",
    "    )\n",
    "    return response_obj\n",
    "\n",
    "\n",
    "def content_summarizer(content_list: list[dict[str, str]],\n",
    "                       summarizer_pipeline: SummarizationPipeline) -> list[dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Summarize a list of cleaned article texts using a Hugging Face summarization pipeline.\n",
    "\n",
    "    Each article in the input list should contain at least \"title\", \"url\", and \"clean_text\".\n",
    "    Summaries are dynamically adjusted in length depending on the article size.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    content_list : list of dict\n",
    "        A list of article dictionaries with keys \"title\", \"url\", and \"clean_text\".\n",
    "    summarizer_pipeline : SummarizationPipeline\n",
    "        A Hugging Face summarization pipeline object.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of dict\n",
    "        A list of dictionaries, each containing:\n",
    "        - \"title\": Article title\n",
    "        - \"url\": Article URL\n",
    "        - \"summary_text\": The generated summary\n",
    "    \"\"\"\n",
    "    summaries: list[dict[str, str]] = []\n",
    "\n",
    "    for content in content_list:\n",
    "        clean_text = content[\"clean_text\"]\n",
    "        r = None\n",
    "        max_length = 200\n",
    "        min_length = 30\n",
    "        try:\n",
    "            word_count = len(clean_text.split(\" \"))\n",
    "\n",
    "            if word_count < 200:\n",
    "                max_length = int(word_count * 0.9)\n",
    "\n",
    "            if word_count < min_length:\n",
    "                min_length = max_length\n",
    "\n",
    "            r = summarizer_pipeline(\n",
    "                clean_text, min_length=min_length, max_length=max_length\n",
    "            )\n",
    "        except IndexError as e:\n",
    "            print(e)\n",
    "            pass\n",
    "        finally:\n",
    "            if r is not None:\n",
    "                summary_obj = {\n",
    "                    \"title\": content[\"title\"],\n",
    "                    \"url\": content[\"url\"],\n",
    "                    \"summary_text\": r[0][\"summary_text\"],\n",
    "                }\n",
    "                summaries.append(summary_obj)\n",
    "\n",
    "    return summaries\n",
    "\n",
    "\n",
    "def meta_summary(summary_list: list[dict[str, str]], \n",
    "                 summarizer_pipeline: SummarizationPipeline) -> list[dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Generate a higher-level meta-summary from a list of individual summaries.\n",
    "\n",
    "    This function concatenates all summaries into a single string and then \n",
    "    applies the summarization pipeline again to produce a longer, \n",
    "    more comprehensive summary.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    summary_list : list of dict\n",
    "        A list of summary dictionaries, each containing at least a \"summary_text\" key.\n",
    "    summarizer_pipeline : SummarizationPipeline\n",
    "        A Hugging Face summarization pipeline object.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of dict\n",
    "        A summarization pipeline output containing the meta-summary text.\n",
    "    \"\"\"\n",
    "    summary_texts = [t[\"summary_text\"] for t in summary_list]\n",
    "    summary_str = \"\".join(summary_texts)\n",
    "\n",
    "    min_length = 100\n",
    "    max_length = 1000\n",
    "    word_count = len(summary_str.split(\" \"))\n",
    "\n",
    "    if word_count < 1000:\n",
    "        max_length = int(word_count * 0.9)\n",
    "\n",
    "    if word_count < min_length:\n",
    "        min_length = max_length\n",
    "\n",
    "    return summarizer_pipeline(summary_str, \n",
    "                               min_length=min_length, max_length=max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db439e75",
   "metadata": {},
   "source": [
    "# Test Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a0c4166b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "ticker = yfinance.Ticker('MSFT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e3e8084a",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_list = [yfinance_pull_clean(n) for n in ticker.news]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ef1b028c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': 'Nebius Group (NASDAQ: NBIS) has emerged as a potential '\n",
      "                  \"superstar in one of the world's biggest growth industries: \"\n",
      "                  'artificial intelligence (AI) The company sells access to '\n",
      "                  'compute, and just recently it signed a multibillion-dollar '\n",
      "                  'deal to provide AI infrastructure to tech giant Microsoft. '\n",
      "                  'Revenue is already taking off at Nebius, as it surged more '\n",
      "                  'than 600% in the recent quarter.',\n",
      "  'title': 'Is Nebius Stock Your Ticket to Becoming a Millionaire?',\n",
      "  'url': 'https://finance.yahoo.com/news/nebius-stock-ticket-becoming-millionaire-172000391.html'},\n",
      " {'summary_text': ' Maximor announced a $9 million seed round to expand its AI '\n",
      "                  'platform. Co-founders Ramnandan Krishnamurthy and Ajay '\n",
      "                  'Krishna Amudan at Microsoft witnessed organizations revert '\n",
      "                  'to spreadsheets despite investments in enterprise resource '\n",
      "                  'planning tools.',\n",
      "  'title': 'Perplexity CEO Aravind Srinivas Backs $9M AI Startup That Cuts '\n",
      "           'Finance Grunt Work By 40% And Slashes Month-End Close In Half',\n",
      "  'url': 'https://finance.yahoo.com/news/perplexity-ceo-aravind-srinivas-backs-143108581.html'},\n",
      " {'summary_text': 'Best AI stocks generate revenue or get a strategic edge '\n",
      "                  'from the fast evolving technology. GOOG O',\n",
      "  'title': \"AI Stocks Face 'Show Me' Test. OpenAI Holds Big Event As Valuation \"\n",
      "           'Soars',\n",
      "  'url': 'https://finance.yahoo.com/m/684c930d-1475-3adc-b013-ae604c056ebc/ai-stocks-face-show-me-.html'},\n",
      " {'summary_text': 'Amazon.com Inc (NASDAQ:AMZN) is one of the stocks that Wall '\n",
      "                  'Street analysts are discussing these days. Amazon offers an '\n",
      "                  'opportunity to bet on the lucrative AI and Cloud market as '\n",
      "                  'well as the behemoth e-commerce market. There are concerns '\n",
      "                  'about AWS growth and rising competition from Oracle and '\n",
      "                  'Microsoft.',\n",
      "  'title': 'Analyst on Amazon (AMZN): ‘AWS Will Accelerate’',\n",
      "  'url': 'https://finance.yahoo.com/news/analyst-amazon-amzn-aws-accelerate-130032397.html'},\n",
      " {'summary_text': 'N Nvidia and Microsoft made large investments in OpenAI. '\n",
      "                  \"Nvidia's move is about keeping its chips at the center of \"\n",
      "                  'the artificial intelligence (AI) infrastructure buildout. '\n",
      "                  \"Microsoft's investment gave it privileged access to \"\n",
      "                  \"OpenAI's AI models.\",\n",
      "  'title': 'Nvidia vs. Microsoft: Which Stock Is the Better Buy After Their '\n",
      "           'OpenAI Investments?',\n",
      "  'url': 'https://finance.yahoo.com/news/nvidia-vs-microsoft-stock-better-111500529.html'},\n",
      " {'summary_text': 'A major agreement dating back to 2023 was revealed in an '\n",
      "                  'SEC filing that includes a $6.3 billion backstop from '\n",
      "                  'Nvidia. The companies both benefit in unique ways from the '\n",
      "                  'arrangement. Building AI data centers is extraordinarily '\n",
      "                  'expensive.',\n",
      "  'title': \"CoreWeave's $6.3 Billion Backstop Deal With Nvidia: What It Means \"\n",
      "           'for Each Company',\n",
      "  'url': 'https://finance.yahoo.com/news/coreweaves-6-3-billion-backstop-103000258.html'},\n",
      " {'summary_text': ' Meta Platforms owns three of the four most popular social '\n",
      "                  'media networks, including Facebook, Instagram, and '\n",
      "                  'WhatsApp. The social media company is using artificial '\n",
      "                  'intelligence to create more engaging experiences across its '\n",
      "                  'social media properties.',\n",
      "  'title': 'The Best Trillion-Dollar AI Stock to Buy Now, According to Wall '\n",
      "           'Street (Hint: Not Nvidia)',\n",
      "  'url': 'https://finance.yahoo.com/news/best-trillion-dollar-ai-stock-074500165.html'},\n",
      " {'summary_text': 'CoreWeave (NASDAQ: CRWV) has swiftly established itself as '\n",
      "                  'a central character in the artificial intelligence (AI) '\n",
      "                  'infrastructure narrative. Its latest milestone -- securing '\n",
      "                  'a six-year, $14.2 billion deal with Meta Platforms -- has '\n",
      "                  'further cemented its position. Neoclouds offer access to '\n",
      "                  'Nvidia GPUs through specialized cloud-based infrastructure.',\n",
      "  'title': 'Should You Buy CoreWeave Stock After the $14 Billion Meta Deal?',\n",
      "  'url': 'https://finance.yahoo.com/news/buy-coreweave-stock-14-billion-074000616.html'},\n",
      " {'summary_text': 'New offering allows conversations with Copilot in '\n",
      "                  'Microsoft’s Office apps like Word, Excel, and PowerPoint. '\n",
      "                  'Microsoft Corporation (NASDAQ:MSFT) is one of the Best '\n",
      "                  'Quantum Computing Stocks to Buy and Hold for 5 Years.',\n",
      "  'title': 'Microsoft (MSFT): New Offering Allows Conversations with Copilot '\n",
      "           'in Office Apps: Reports CNBC',\n",
      "  'url': 'https://finance.yahoo.com/news/microsoft-msft-offering-allows-conversations-211547910.html'},\n",
      " {'summary_text': \"Microsoft's enterprise-focused AI strategy offers it \"\n",
      "                  'greater resiliency. Alphabet and Amazon may face some '\n",
      "                  'challenges despite advances in AI. Increasing adoption of '\n",
      "                  'cloud computing is also a significant growth catalyst.',\n",
      "  'title': 'Prediction: 1 Artificial Intelligence (AI) Stock Will Be Worth '\n",
      "           'More Than Alphabet and Amazon Combined by 2030 (Hint: Not Nvidia)',\n",
      "  'url': 'https://finance.yahoo.com/news/prediction-1-artificial-intelligence-ai-154500272.html'}]\n"
     ]
    }
   ],
   "source": [
    "summary_list = content_summarizer(content_list, summarizer)\n",
    "pprint(summary_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "75792d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Nebius Group (NASDAQ: NBIS) has emerged as a potential superstar in one of '\n",
      " \"the world's biggest growth industries: artificial intelligence. Revenue is \"\n",
      " 'already taking off at Nebius, as it surged more than 600% in the recent '\n",
      " \"quarter. Nvidia and Microsoft made large investments in OpenAI. Microsoft's \"\n",
      " \"investment gave it privileged access to OpenAI's AI models. Amazon offers an \"\n",
      " 'opportunity to bet on the lucrative AI and Cloud market as well as the '\n",
      " 'behemoth e-commerce market.')\n"
     ]
    }
   ],
   "source": [
    "m_summary = meta_summary(summary_list, summarizer)\n",
    "pprint(m_summary[0][\"summary_text\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_final_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
