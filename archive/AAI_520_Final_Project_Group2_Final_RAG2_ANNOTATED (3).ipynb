{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TWvFHgdwIuRh",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q sentence-transformers==3.0.1 scikit-learn==1.5.1 yfinance fredapi pandas textblob matplotlib fpdf seaborn transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geLpKggSSmeT",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/dl_final_project/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-10-18 10:04:32.788326: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. Configuration directories created/verified.\n",
      "FRED API initialized.\n",
      "LLM (BART) initialized for synthesis.\n"
     ]
    }
   ],
   "source": [
    "# Import\n",
    "import yfinance as yf\n",
    "from yfinance.ticker import Ticker\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from fredapi import Fred\n",
    "from textblob import TextBlob\n",
    "from fpdf import FPDF\n",
    "from IPython.display import display\n",
    "import os\n",
    "import datetime\n",
    "import hashlib\n",
    "import json\n",
    "import warnings\n",
    "import string\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Setup FRED\n",
    "FRED_API_KEY = os.environ.get(\n",
    "    \"FRED_API_KEY\", \"e9b13c9f61d9447309d4c104b82a45d1\")\n",
    "fred = Fred(api_key=FRED_API_KEY)\n",
    "CONFIG = {\"memory_dir\": \"memory\", \"report_dir\": \"reports\"}\n",
    "\n",
    "# Create necessary directories\n",
    "os.makedirs(CONFIG[\"memory_dir\"], exist_ok=True)\n",
    "os.makedirs(CONFIG[\"report_dir\"], exist_ok=True)\n",
    "\n",
    "# Initialize LLM for synthesis\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "synthesis_llm = pipeline(\n",
    "    \"summarization\", model=\"facebook/bart-large-cnn\", device=device)\n",
    "\n",
    "print(\"Setup complete. Configuration directories created/verified.\")\n",
    "print(\"FRED API initialized.\")\n",
    "print(\"LLM (BART) initialized for synthesis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "n7wxJtm_So9F",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA HANDLING, FETCHING, AND CORE ANALYSIS FUNCTIONS\n",
    "# Persistent learning across runs ‚Äî loads prior notes for a ticker to influence future analyses\n",
    "def load_memory(ticker):\n",
    "    \"\"\"Loads a ticker's persistent notes/summary from a file.\"\"\"\n",
    "    path = os.path.join(CONFIG[\"memory_dir\"], f\"{ticker}.json\")\n",
    "    return json.load(open(path)) if os.path.exists(path) else {\"notes\": \"No prior analysis\", \"last_run\": None}\n",
    "\n",
    "# Persistent learning across runs ‚Äî saves notes/summary after each run to improve future analyses\n",
    "\n",
    "\n",
    "def save_memory(ticker, data):\n",
    "    \"\"\"Saves a ticker's notes/summary for future runs.\"\"\"\n",
    "    path = os.path.join(CONFIG[\"memory_dir\"], f\"{ticker}.json\")\n",
    "    json.dump(data, open(path, \"w\"), indent=2)\n",
    "\n",
    "# Dynamic tool use via Yahoo Finance API/dataset ‚Äî fetches historical OHLCV and news for a ticker\n",
    "\n",
    "\n",
    "def fetch_yfinance_data(ticker):\n",
    "    \"\"\"Tool: Fetches historical prices (1y) and news using yfinance.\"\"\"\n",
    "    print(f\"    [Tool Use] Fetching yfinance data for {ticker}...\")\n",
    "    try:\n",
    "        t = yf.Ticker(ticker)\n",
    "        hist = t.history(period=\"1y\").reset_index()\n",
    "        news = t.news or []\n",
    "        return hist, news\n",
    "    except Exception as e:\n",
    "        print(\n",
    "            f\"        [Error] Failed to fetch yfinance data for {ticker}: {e}\")\n",
    "        return pd.DataFrame(), []\n",
    "\n",
    "# Dynamic tool use via FRED API ‚Äî fetches macroeconomic time series (e.g., CPIAUCSL)\n",
    "\n",
    "\n",
    "def fetch_fred_data(series_id):\n",
    "    \"\"\"Tool: Fetches economic data using FRED API (e.g., CPIAUCSL).\"\"\"\n",
    "    try:\n",
    "        s = fred.get_series(series_id)\n",
    "        if s is None or s.empty:\n",
    "            return pd.DataFrame()\n",
    "        df = pd.DataFrame(s).reset_index()\n",
    "        data_col_name = df.columns[-1]\n",
    "        df.rename(columns={data_col_name: series_id,\n",
    "                  'index': 'date'}, inplace=True)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"        Error fetching FRED data: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Dynamic tool ‚Äî technical indicator for price analysis (RSI)\n",
    "\n",
    "\n",
    "def compute_rsi(series, window=14):\n",
    "    \"\"\"Tool: Computes Relative Strength Index (RSI).\"\"\"\n",
    "    delta = series.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window).mean()\n",
    "    rsi = 100 - (100 / (1 + gain / loss))\n",
    "    return rsi\n",
    "\n",
    "# Prompt Chaining ‚Äî Preprocess, Classify, Extract news via weighted sentiment & tone\n",
    "\n",
    "\n",
    "def news_impact_analyzer(news_list, ticker):\n",
    "    \"\"\"Workflow: Sentiment analysis with simulated NER/POS filtering.\"\"\"\n",
    "    results = []\n",
    "    high_impact_keywords = [\"acquire\", \"launch\",\n",
    "                            \"missed\", \"soared\", \"failed\", \"record\", \"major\"]\n",
    "    for n in news_list:\n",
    "        t = n.get(\"title\", \"\").lower()\n",
    "        if t:\n",
    "            s = TextBlob(t).sentiment.polarity\n",
    "            is_high_impact = any(\n",
    "                k in t for k in high_impact_keywords) and ticker.lower() in t.lower()\n",
    "            sentiment_weight = 1.0 if is_high_impact else 0.5\n",
    "            weighted_s = s * sentiment_weight\n",
    "            tone = \"positive\" if weighted_s > 0.1 else \"negative\" if weighted_s < -0.1 else \"neutral\"\n",
    "            results.append({\"title\": n.get(\"title\", \"\"), \"sentiment\": round(\n",
    "                s, 2), \"weighted_sentiment\": round(weighted_s, 2), \"tone\": tone})\n",
    "    df = pd.DataFrame(results)\n",
    "    overall_sentiment = df['weighted_sentiment'].mean() if not df.empty else 0\n",
    "    return df, overall_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "rlK3FJZOWKbz",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZATION FUNCTIONS\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Dynamic tool ‚Äî visualization function for price & RSI evidence in the report\n",
    "def plot_price_and_rsi(df, ticker, rsi):\n",
    "    \"\"\"Tool: Plots stock price and RSI and saves the image.\"\"\"\n",
    "    if df.empty or rsi.empty:\n",
    "        return None\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 6), sharex=True)\n",
    "    ax1.plot(df[\"Date\"], df[\"Close\"], label=\"Close\", color='darkblue', linewidth=1.5)\n",
    "    ax1.plot(df[\"Date\"], df[\"Close\"].rolling(50).mean(), label=\"MA-50\", color='orange', linestyle='--')\n",
    "    ax1.plot(df[\"Date\"], df[\"Close\"].rolling(200).mean(), label=\"MA-200\", color='red', linestyle='--')\n",
    "    ax1.set_title(f\"{ticker} Price and Moving Averages\", fontsize=14)\n",
    "    ax1.legend(loc='upper left')\n",
    "    ax1.tick_params(axis='y', labelcolor='darkblue')\n",
    "    ax2.plot(df[\"Date\"], rsi, label=\"RSI-14\", color=\"purple\", linewidth=1.5)\n",
    "    ax2.axhline(70, color='red', linestyle=\"--\", alpha=0.7, label=\"Overbought\")\n",
    "    ax2.axhline(30, color='green', linestyle=\"--\", alpha=0.7, label=\"Oversold\")\n",
    "    ax2.set_ylim(0, 100)\n",
    "    ax2.legend(loc='upper left')\n",
    "    ax2.set_title(\"RSI Trends\", fontsize=14)\n",
    "    ax2.set_xlabel(\"Date\")\n",
    "    path = f\"{CONFIG['report_dir']}/{ticker}_price_rsi.png\"\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path, dpi=100)\n",
    "    plt.close()\n",
    "    print(f\"        [Chart] Generated Price & RSI chart: {os.path.basename(path)}\")\n",
    "    return path\n",
    "\n",
    "# Dynamic tool ‚Äî visualization of macro correlation (e.g., CPI vs price)\n",
    "def plot_macro_correlation(stock_df, macro_df, ticker, macro_key):\n",
    "    \"\"\"Tool: Plots price vs macro indicator, returns correlation, and saves the image.\"\"\"\n",
    "    stock_df_fixed = stock_df.copy()\n",
    "    if pd.api.types.is_datetime64_any_dtype(stock_df_fixed[\"Date\"]) and stock_df_fixed[\"Date\"].dt.tz is not None:\n",
    "        stock_df_fixed[\"Date\"] = stock_df_fixed[\"Date\"].dt.tz_localize(None)\n",
    "    merged = pd.merge(stock_df_fixed, macro_df, left_on=\"Date\", right_on=\"date\", how=\"inner\")\n",
    "    if merged.empty or len(merged) < 5:\n",
    "        return None, None\n",
    "    corr = merged[[\"Close\", macro_key]].corr().iloc[0, 1]\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "    ax1.plot(merged[\"Date\"], merged[\"Close\"], label=f\"{ticker} Close\", color=\"blue\")\n",
    "    ax1.set_xlabel(\"Date\")\n",
    "    ax1.set_ylabel(f\"{ticker} Close Price\", color=\"blue\")\n",
    "    ax1.tick_params(axis='y', labelcolor=\"blue\")\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(merged[\"date\"], merged[macro_key], label=macro_key.upper(), color=\"orange\", linestyle=\"--\")\n",
    "    ax2.set_ylabel(macro_key.upper(), color=\"orange\")\n",
    "    ax2.tick_params(axis='y', labelcolor=\"orange\")\n",
    "    plt.title(f\"{ticker} vs {macro_key.upper()} (Correlation: {corr:.2f})\", fontsize=14)\n",
    "    lines, labels = ax1.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    ax2.legend(lines + lines2, labels + labels2, loc='upper left')\n",
    "    path = f\"{CONFIG['report_dir']}/{ticker}_{macro_key}_corr.png\"\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path, dpi=100)\n",
    "    plt.close()\n",
    "    print(f\"        [Chart] Generated Macro Correlation chart: {os.path.basename(path)}\")\n",
    "    return path, corr\n",
    "\n",
    "# Dynamic tool ‚Äî visualization of **Classify** stage (sentiment distribution)\n",
    "def plot_sentiment_distribution(df, ticker):\n",
    "    \"\"\"Tool: Plots news sentiment distribution and saves the image.\"\"\"\n",
    "    if df.empty:\n",
    "        return None\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    colors = ['green' if x == 'positive' else 'red' if x == 'negative' else 'gray' for x in df[\"tone\"].value_counts().index]\n",
    "    df[\"tone\"].value_counts().plot(kind=\"bar\", color=colors, alpha=0.7)\n",
    "    plt.title(f\"News Sentiment Distribution ({ticker})\", fontsize=14)\n",
    "    plt.xticks(rotation=0, ha='center')\n",
    "    plt.ylabel(\"Number of Articles\")\n",
    "    plt.xlabel(\"Sentiment Tone\")\n",
    "    path = f\"{CONFIG['report_dir']}/{ticker}_sentiment.png\"\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path, dpi=100)\n",
    "    plt.close()\n",
    "    print(f\"        [Chart] Generated Sentiment chart: {os.path.basename(path)}\")\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RdC6tstxStlo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPECIALIST AGENT CLASSES\n",
    "# PriceAnalyzer Agent: PriceAnalyzer handles RSI & trend regime\n",
    "class PriceAnalyzer:\n",
    "    \"\"\"Specialist: Analyzes price data, calculating RSI and trend regime.\"\"\"\n",
    "\n",
    "    def analyze(self, hist):\n",
    "        if hist.empty or \"Close\" not in hist.columns or len(hist) < 20:\n",
    "            print(\n",
    "                \"        [Warning] PriceAnalyzer received insufficient historical data.\")\n",
    "            return {\"rsi\": None, \"regime\": \"N/A (Data Unavailable)\"}\n",
    "        rsi = compute_rsi(hist[\"Close\"])\n",
    "        if rsi.empty or rsi.iloc[-1].item() is np.nan:\n",
    "            rsi_value = None\n",
    "            regime = \"N/A (Insufficient Data)\"\n",
    "        else:\n",
    "            rsi_value = rsi.iloc[-1].item()\n",
    "            ma_20 = hist[\"Close\"].rolling(20).mean().iloc[-1]\n",
    "            regime = \"Uptrend\" if hist[\"Close\"].iloc[-1] > ma_20 else \"Downtrend\"\n",
    "        return {\"rsi\": rsi_value, \"regime\": regime}\n",
    "\n",
    "# MacroAnalyzer Agent handles FRED macro signal & correlations\n",
    "\n",
    "\n",
    "class MacroAnalyzer:\n",
    "    \"\"\"Specialist: Analyzes macro-economic data and correlation (default: CPI).\"\"\"\n",
    "\n",
    "    def analyze(self, hist, ticker, macro_key=\"CPIAUCSL\"):\n",
    "        macro = fetch_fred_data(macro_key)\n",
    "        path, corr = plot_macro_correlation(hist, macro, ticker, macro_key)\n",
    "        return {\"corr\": corr, \"plot_path\": path}\n",
    "\n",
    "# NewsAnalyzer Agent computes weighted sentiment & tone\n",
    "\n",
    "\n",
    "class NewsAnalyzer:\n",
    "    \"\"\"Specialist: Analyzes news sentiment using the weighted scoring logic.\"\"\"\n",
    "\n",
    "    def analyze(self, news, ticker):\n",
    "        df, sentiment = news_impact_analyzer(news, ticker)\n",
    "        return {\"sentiment\": sentiment, \"news_df\": df, \"num_news\": len(df)}\n",
    "\n",
    "# NewsSummarizer Agent: Ingest (fetch) ‚Üí Preprocess/clean ‚Üí Summarize news articles\n",
    "\n",
    "\n",
    "class NewsSummarizer:\n",
    "    \"\"\"Specialist: Summarizes news articles for a ticker.\"\"\"\n",
    "\n",
    "    def __init__(self, summarizer, ticker):\n",
    "        self.summarizer = summarizer\n",
    "        self.ticker = ticker\n",
    "        self.content_list = []\n",
    "        self.content_summaries = []\n",
    "        self.meta_summary = None\n",
    "\n",
    "# Ingest & Preprocess ‚Äî pulls article pages, strips HTML, normalizes text\n",
    "    def fetch_and_clean(self):\n",
    "        \"\"\"Fetches and cleans news articles.\"\"\"\n",
    "        _, news = fetch_yfinance_data(self.ticker.ticker)\n",
    "        for article in news:\n",
    "            try:\n",
    "                response = requests.get(article.get(\"link\", \"\"), timeout=5)\n",
    "                soup = BeautifulSoup(response.text, 'html.parser')\n",
    "                text = ' '.join(p.get_text() for p in soup.find_all('p'))\n",
    "                text = re.sub(r'\\s+', ' ', text).strip()\n",
    "                if text and len(text) > 50:\n",
    "                    self.content_list.append(text[:1000])\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "# Summarize ‚Äî distills multi‚Äëarticle content into concise meta‚Äësummary via LLM\n",
    "    def summarize(self):\n",
    "        \"\"\"Summarizes articles and generates meta-summary.\"\"\"\n",
    "        self.fetch_and_clean()\n",
    "        for content in self.content_list:\n",
    "            try:\n",
    "                summary = self.summarizer(content, max_length=60, min_length=20, do_sample=False)[\n",
    "                    0]['summary_text']\n",
    "                self.content_summaries.append(summary)\n",
    "            except:\n",
    "                continue\n",
    "        if self.content_summaries:\n",
    "            combined = \" \".join(self.content_summaries)\n",
    "            self.meta_summary = self.summarizer(\n",
    "                combined, max_length=100, min_length=40, do_sample=False)[0]['summary_text']\n",
    "        return self.meta_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gyfOptJZWQl5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AGENT AND PROMPT MANAGER\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Routing workflow ‚Äî directs request to single‚Äëticker vs two‚Äëticker pipelines and downstream specialists\n",
    "\n",
    "\n",
    "class PromptManager:\n",
    "    \"\"\"Manages prompt execution and routing to specialists or LLM.\"\"\"\n",
    "\n",
    "    def __init__(self, agent):\n",
    "        self.agent = agent\n",
    "\n",
    "    def execute_prompt(self, prompt, ticker=None, ticker2=None):\n",
    "        print(f\"\\nProcessing prompt: {prompt}\")\n",
    "        if ticker and ticker2:\n",
    "            result1 = self.agent.analyze_ticker(ticker)\n",
    "            result2 = self.agent.analyze_ticker(ticker2)\n",
    "            self.agent.synthesize_comparison(\n",
    "                prompt, ticker, result1, ticker2, result2)\n",
    "        elif ticker:\n",
    "            result = self.agent.analyze_ticker(ticker)\n",
    "            self.agent.synthesize_response(prompt, ticker, result)\n",
    "\n",
    "\n",
    "class InvestmentResearchAgent:\n",
    "    \"\"\"Autonomous Investment Research Agent coordinating specialists and LLM.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.price_analyzer = PriceAnalyzer()\n",
    "        self.macro_analyzer = MacroAnalyzer()\n",
    "        self.news_analyzer = NewsAnalyzer()\n",
    "        self.news_summarizer = NewsSummarizer(synthesis_llm, yf.Ticker)\n",
    "        self.llm = synthesis_llm\n",
    "\n",
    "# Planning research steps ‚Äî orchestrates sequence: load memory ‚Üí fetch data ‚Üí run specialists ‚Üí summarize ‚Üí visualize ‚Üí persist\n",
    "    def analyze_ticker(self, ticker):\n",
    "        \"\"\"Analyzes a single ticker using specialists.\"\"\"\n",
    "        print(f\"Analyzing {ticker}...\")\n",
    "        memory = load_memory(ticker)\n",
    "        print(\n",
    "            f\"    [Agent Learns] Prior Notes ({memory['last_run']}): {memory['notes']}\")\n",
    "        hist, news = fetch_yfinance_data(ticker)\n",
    "        price_result = self.price_analyzer.analyze(hist)\n",
    "        macro_result = self.macro_analyzer.analyze(hist, ticker)\n",
    "        news_result = self.news_analyzer.analyze(news, ticker)\n",
    "        sentiment_plot = plot_sentiment_distribution(\n",
    "            news_result['news_df'], ticker)\n",
    "        self.news_summarizer.ticker = yf.Ticker(ticker)\n",
    "        summary = self.news_summarizer.summarize()\n",
    "        # Generate Price & RSI chart\n",
    "        rsi = compute_rsi(hist[\"Close\"]) if not hist.empty else pd.Series()\n",
    "        price_rsi_plot = plot_price_and_rsi(hist, ticker, rsi)\n",
    "        # Display charts inline\n",
    "        print(f\"\\n============================================================\\n\"\n",
    "              f\"               üìä Final Investment Report for {ticker}\\n\"\n",
    "              f\"============================================================\\n\"\n",
    "              f\"üí° Key Findings:\\n\"\n",
    "              f\"  - Current RSI (14): {price_result['rsi'] or 'N/A'}, Regime: {price_result['regime']}\\n\"\n",
    "              f\"  - Macro Correlation (CPI): {macro_result['corr'] or 'N/A'}\\n\"\n",
    "              f\"  - News Sentiment (Weighted): {news_result['sentiment']:.2f} from {news_result['num_news']} articles\\n\"\n",
    "              f\"\\nüìù Agent Metrics & Reflection (Evaluator-Optimizer Output)\\n\"\n",
    "              f\"  - Data Summary: RSI is {price_result['rsi'] or 'N/A'}, Trend: {price_result['regime']}. \"\n",
    "              f\"CPI Correlation: {macro_result['corr'] or 'N/A'}. Weighted News Sentiment: {news_result['sentiment']:.2f}.\\n\")\n",
    "        print(\"üìà Visual Evidence:\")\n",
    "        if price_rsi_plot:\n",
    "            print(f\"  Displaying: {os.path.basename(price_rsi_plot)}\")\n",
    "            display(Image(filename=price_rsi_plot))\n",
    "        if macro_result['plot_path']:\n",
    "            print(\n",
    "                f\"  Displaying: {os.path.basename(macro_result['plot_path'])}\")\n",
    "            display(Image(filename=macro_result['plot_path']))\n",
    "        if sentiment_plot:\n",
    "            print(f\"  Displaying: {os.path.basename(sentiment_plot)}\")\n",
    "            display(Image(filename=sentiment_plot))\n",
    "        print(\"============================================================\\n\")\n",
    "        result = {\n",
    "            \"price\": price_result,\n",
    "            \"macro\": macro_result,\n",
    "            \"news\": news_result,\n",
    "            \"summary\": summary,\n",
    "            \"sentiment_plot\": sentiment_plot,\n",
    "            \"price_rsi_plot\": price_rsi_plot,\n",
    "            \"memory\": memory\n",
    "        }\n",
    "        save_memory(ticker, {\"notes\": summary or \"No summary\",\n",
    "                    \"last_run\": str(datetime.datetime.now())})\n",
    "        return result\n",
    "\n",
    "# Self‚Äëreflection & Evaluator‚ÄëOptimizer ‚Äî generate analysis, score confidence, use prior notes for feedback/refinement\n",
    "    def synthesize_response(self, prompt, ticker, result):\n",
    "        \"\"\"Generates response using LLM for a single ticker.\"\"\"\n",
    "        print(f\"SynthesisAgent (LLM) Generating Response...\")\n",
    "        input_text = (\n",
    "            f\"Prompt: {prompt}\\n\"\n",
    "            f\"Ticker: {ticker}\\n\"\n",
    "            f\"RSI: {result['price']['rsi'] or 'N/A'}\\n\"\n",
    "            f\"Price Regime: {result['price']['regime']}\\n\"\n",
    "            f\"Macro Correlation (CPI): {result['macro']['corr'] or 'N/A'}\\n\"\n",
    "            f\"News Sentiment: {result['news']['sentiment']:.2f}\\n\"\n",
    "            f\"News Summary: {result['summary'] or 'No summary'}\\n\"\n",
    "            f\"Prior Notes: {result['memory']['notes']}\\n\"\n",
    "            f\"Generate a concise analysis with a confidence score (0-1) and key insights.\"\n",
    "        )\n",
    "        try:\n",
    "            llm_output = self.llm(input_text, max_length=150, min_length=50, do_sample=False)[\n",
    "                0]['summary_text']\n",
    "            confidence = float(re.search(r'Confidence: (\\d\\.\\d+)', llm_output).group(\n",
    "                1)) if re.search(r'Confidence: (\\d\\.\\d+)', llm_output) else 0.5\n",
    "            print(f\"\\n============================================================\\n\"\n",
    "                  f\"             ‚ú® Final User-Facing Response ‚ú®\\n\"\n",
    "                  f\"============================================================\\n\"\n",
    "                  f\"### Comprehensive Summary for {ticker}\\n\"\n",
    "                  f\"**Agent Confidence:** {confidence}\\n\\n\"\n",
    "                  f\"**Key Analytical Insights:**\\n\"\n",
    "                  f\"{llm_output}\\n\"\n",
    "                  f\"\\n**Agent Data Conclusion:** *RSI is {result['price']['rsi'] or 'N/A'}, \"\n",
    "                  f\"Trend: {result['price']['regime']}. CPI Correlation: {result['macro']['corr'] or 'N/A'}. \"\n",
    "                  f\"Weighted News Sentiment: {result['news']['sentiment']:.2f}.*\\n\"\n",
    "                  f\"============================================================\\n\")\n",
    "            return {\"text\": llm_output, \"confidence\": confidence}\n",
    "        except Exception as e:\n",
    "            print(f\"LLM synthesis failed: {e}\")\n",
    "            return {\"text\": \"Analysis failed\", \"confidence\": 0.5}\n",
    "\n",
    "# Routing + Evaluator‚ÄëOptimizer for pairwise comparison (two specialists pipelines, then LLM synthesis)\n",
    "    def synthesize_comparison(self, prompt, ticker1, result1, ticker2, result2):\n",
    "        \"\"\"Generates comparison using LLM for two tickers.\"\"\"\n",
    "        print(f\"SynthesisAgent (LLM) Generating Response...\")\n",
    "        input_text = (\n",
    "            f\"Prompt: {prompt}\\n\"\n",
    "            f\"Ticker 1: {ticker1}\\n\"\n",
    "            f\"RSI: {result1['price']['rsi'] or 'N/A'}\\n\"\n",
    "            f\"Price Regime: {result1['price']['regime']}\\n\"\n",
    "            f\"Macro Correlation (CPI): {result1['macro']['corr'] or 'N/A'}\\n\"\n",
    "            f\"News Sentiment: {result1['news']['sentiment']:.2f}\\n\"\n",
    "            f\"News Summary: {result1['summary'] or 'No summary'}\\n\"\n",
    "            f\"Ticker 2: {ticker2}\\n\"\n",
    "            f\"RSI: {result2['price']['rsi'] or 'N/A'}\\n\"\n",
    "            f\"Price Regime: {result2['price']['regime']}\\n\"\n",
    "            f\"Macro Correlation (CPI): {result2['macro']['corr'] or 'N/A'}\\n\"\n",
    "            f\"News Sentiment: {result2['news']['sentiment']:.2f}\\n\"\n",
    "            f\"News Summary: {result2['summary'] or 'No summary'}\\n\"\n",
    "            f\"Compare the two tickers, provide a confidence score (0-1), and highlight strengths.\"\n",
    "        )\n",
    "        try:\n",
    "            llm_output = self.llm(input_text, max_length=200, min_length=80, do_sample=False)[\n",
    "                0]['summary_text']\n",
    "            confidence = float(re.search(r'Confidence: (\\d\\.\\d+)', llm_output).group(\n",
    "                1)) if re.search(r'Confidence: (\\d\\.\\d+)', llm_output) else 0.5\n",
    "            print(f\"\\n============================================================\\n\"\n",
    "                  f\"             ‚ú® Final User-Facing Response ‚ú®\\n\"\n",
    "                  f\"============================================================\\n\"\n",
    "                  f\"### Comparative Analysis: {ticker1} vs {ticker2}\\n\"\n",
    "                  f\"**Query Intent:** Comparison (Address: *{prompt}*)\\n\")\n",
    "            display(pd.DataFrame({\n",
    "                \"Metric\": [\"Agent Confidence\", \"RSI (14)\", \"Price Regime\", \"Macro Corr (CPI)\", \"Weighted Sentiment\"],\n",
    "                ticker1: [confidence, result1['price']['rsi'] or 'N/A', result1['price']['regime'], result1['macro']['corr'] or 'N/A', result1['news']['sentiment']],\n",
    "                ticker2: [confidence, result2['price']['rsi'] or 'N/A', result2['price']\n",
    "                    ['regime'], result2['macro']['corr'] or 'N/A', result2['news']['sentiment']]\n",
    "            }))\n",
    "            print(f\"\\n**Synthesis Conclusion:**\\n{llm_output}\\n\")\n",
    "\n",
    "            # Display charts for both tickers\n",
    "            print(\"üìà Visual Evidence:\")\n",
    "            if result1['price_rsi_plot']:\n",
    "                print(\n",
    "                    f\"  Displaying: {os.path.basename(result1['price_rsi_plot'])}\")\n",
    "                display(Image(filename=result1['price_rsi_plot']))\n",
    "            if result1['macro']['plot_path']:\n",
    "                print(\n",
    "                    f\"  Displaying: {os.path.basename(result1['macro']['plot_path'])}\")\n",
    "                display(Image(filename=result1['macro']['plot_path']))\n",
    "            if result1['sentiment_plot']:\n",
    "                print(\n",
    "                    f\"  Displaying: {os.path.basename(result1['sentiment_plot'])}\")\n",
    "                display(Image(filename=result1['sentiment_plot']))\n",
    "            if result2['price_rsi_plot']:\n",
    "                print(\n",
    "                    f\"  Displaying: {os.path.basename(result2['price_rsi_plot'])}\")\n",
    "                display(Image(filename=result2['price_rsi_plot']))\n",
    "            if result2['macro']['plot_path']:\n",
    "                print(\n",
    "                    f\"  Displaying: {os.path.basename(result2['macro']['plot_path'])}\")\n",
    "                display(Image(filename=result2['macro']['plot_path']))\n",
    "            if result2['sentiment_plot']:\n",
    "                print(\n",
    "                    f\"  Displaying: {os.path.basename(result2['sentiment_plot'])}\")\n",
    "                display(Image(filename=result2['sentiment_plot']))\n",
    "            print(\"============================================================\\n\")\n",
    "            return {\"text\": llm_output, \"confidence\": confidence}\n",
    "        except Exception as e:\n",
    "            print(f\"LLM comparison failed: {e}\")\n",
    "            return {\"text\": \"Comparison failed\", \"confidence\": 0.5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "YjbMHZZpIuRk",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG Setup\n",
    "import os, json, numpy as np\n",
    "from typing import List, Dict, Any\n",
    "try:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\"Please run the setup cell to install sentence-transformers.\") from e\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "class RAGStore:\n",
    "    \"\"\"\n",
    "    Lightweight local RAG index: stores docs + embeddings on disk and retrieves with cosine similarity.\n",
    "    Path layout:\n",
    "      <base_path>/docs.json\n",
    "      <base_path>/embeddings.npy\n",
    "    \"\"\"\n",
    "    def __init__(self, base_path: str, model_name: str = \"all-MiniLM-L6-v2\"):\n",
    "        self.base_path = base_path\n",
    "        os.makedirs(self.base_path, exist_ok=True)\n",
    "        self.docs_path = os.path.join(self.base_path, \"docs.json\")\n",
    "        self.vecs_path = os.path.join(self.base_path, \"embeddings.npy\")\n",
    "        self.model_name = model_name\n",
    "        self.model = SentenceTransformer(self.model_name)\n",
    "        self.docs: List[Dict[str, Any]] = []\n",
    "        self.vecs = None\n",
    "        self.nn = None\n",
    "        if os.path.exists(self.docs_path) and os.path.exists(self.vecs_path):\n",
    "            try:\n",
    "                with open(self.docs_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                    self.docs = json.load(f)\n",
    "                self.vecs = np.load(self.vecs_path)\n",
    "                if len(self.docs) == len(self.vecs):\n",
    "                    self.nn = NearestNeighbors(metric=\"cosine\").fit(self.vecs)\n",
    "            except Exception:\n",
    "                self.docs, self.vecs, self.nn = [], None, None\n",
    "\n",
    "    def _save(self):\n",
    "        with open(self.docs_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(self.docs, f, ensure_ascii=False, indent=2)\n",
    "        if self.vecs is not None:\n",
    "            np.save(self.vecs_path, self.vecs)\n",
    "\n",
    "    def upsert(self, docs: List[Dict[str, Any]], text_key: str = \"text\", id_key: str = \"id\"):\n",
    "        existing = {d.get(id_key) for d in self.docs if id_key in d}\n",
    "        new_docs = [d for d in docs if d.get(id_key) not in existing]\n",
    "        if not new_docs:\n",
    "            return 0\n",
    "        texts = [d.get(text_key, \"\") or \"\" for d in new_docs]\n",
    "        if not any(texts):\n",
    "            return 0\n",
    "        new_vecs = self.model.encode(texts, normalize_embeddings=True)\n",
    "        self.docs.extend(new_docs)\n",
    "        self.vecs = new_vecs if self.vecs is None else np.vstack([self.vecs, new_vecs])\n",
    "        self.nn = NearestNeighbors(metric=\"cosine\").fit(self.vecs)\n",
    "        self._save()\n",
    "        return len(new_docs)\n",
    "\n",
    "    def retrieve(self, query: str, k: int = 8):\n",
    "        if not self.nn or self.vecs is None or not len(self.docs):\n",
    "            return []\n",
    "        qv = self.model.encode([query], normalize_embeddings=True)\n",
    "        k = min(k, len(self.docs))\n",
    "        dists, idxs = self.nn.kneighbors(qv, n_neighbors=k)\n",
    "        return [self.docs[i] for i in idxs[0]]\n",
    "\n",
    "def news_to_rag_docs(news_list: List[Dict[str, Any]], ticker: str) -> List[Dict[str, Any]]:\n",
    "    docs = []\n",
    "    for i, n in enumerate(news_list or []):\n",
    "        doc_id = n.get(\"uuid\") or n.get(\"id\") or n.get(\"link\") or f\"{ticker}-{i}\"\n",
    "        title = n.get(\"title\") or n.get(\"headline\") or \"(no title)\"\n",
    "        text = n.get(\"text\") or n.get(\"content\") or n.get(\"summary\") or title\n",
    "        meta = {\n",
    "            \"ticker\": ticker,\n",
    "            \"publisher\": n.get(\"publisher\"),\n",
    "            \"published\": n.get(\"providerPublishTime\") or n.get(\"published\"),\n",
    "            \"link\": n.get(\"link\"),\n",
    "        }\n",
    "        docs.append({\"id\": doc_id, \"title\": title, \"text\": str(text), \"meta\": meta})\n",
    "    return docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "PL0vy1FvIuRk",
   "metadata": {},
   "outputs": [],
   "source": [
    "# News Summarizer with RAG\n",
    "from typing import Optional\n",
    "\n",
    "def summarize_news_with_rag(bart_pipeline, ticker: str, base_dir: str = \"memory\", task: str = \"investor briefing\", fallback_fn=None) -> Optional[str]:\n",
    "    rag = RAGStore(os.path.join(base_dir, ticker, \"rag\"))\n",
    "    ctx = rag.retrieve(f\"{ticker} catalysts guidance regulation litigation product launches earnings macro linkages\", k=8)\n",
    "    if not ctx:\n",
    "        if callable(fallback_fn):\n",
    "            return fallback_fn(ticker)\n",
    "        return None\n",
    "    context = \"\\n\\n\".join([f\"[{i+1}] {d['title']}\\n{d['text'][:1200]}\" for i, d in enumerate(ctx)])\n",
    "    prompt = (\n",
    "        f\"Summarize recent news for {ticker} for {task}. \"\n",
    "        f\"Focus on catalysts, risks, guidance, litigation/regulatory, and timeline. \"\n",
    "        f\"Use ONLY the CONTEXT below; be concise.\\n\\nCONTEXT:\\n{context}\\n\\nBRIEFING:\"\n",
    "    )\n",
    "    try:\n",
    "        out = bart_pipeline(prompt, max_length=350, do_sample=False)\n",
    "        return out[0][\"summary_text\"]\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "try:\n",
    "    class NewsSummarizerRAG(NewsSummarizer):\n",
    "\n",
    "# Summarize ‚Äî distills multi‚Äëarticle content into concise meta‚Äësummary via LLM\n",
    "        def summarize(self, ticker: str, *args, **kwargs):\n",
    "            fb = getattr(super(), \"summarize\", None)\n",
    "            return summarize_news_with_rag(self.pipeline, ticker, fallback_fn=fb)\n",
    "except NameError:\n",
    "    class NewsSummarizerRAG:\n",
    "        def __init__(self, pipeline):\n",
    "            self.pipeline = pipeline\n",
    "        def summarize(self, ticker: str, *_, **__):\n",
    "            return summarize_news_with_rag(self.pipeline, ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ry8uRfoTIuRk",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment / Impact prefilter with RAG\n",
    "DEFAULT_TOPICS = [\"earnings\", \"guidance\", \"lawsuit\", \"regulation\", \"M&A\", \"product\", \"supply chain\"]\n",
    "\n",
    "def prefilter_news_with_rag(ticker: str, base_dir: str = \"memory\", topics=None, k_per_topic: int = 3):\n",
    "    topics = topics or DEFAULT_TOPICS\n",
    "    rag = RAGStore(os.path.join(base_dir, ticker, \"rag\"))\n",
    "    picked = []\n",
    "    seen = set()\n",
    "    for t in topics:\n",
    "        for d in rag.retrieve(f\"{ticker} {t}\", k=k_per_topic):\n",
    "            if d[\"id\"] not in seen:\n",
    "                picked.append(d)\n",
    "                seen.add(d[\"id\"])\n",
    "    return picked\n",
    "\n",
    "def news_impact_analyzer_rag(ticker: str, original_news_list: list, analyzer_fn):\n",
    "    subset = prefilter_news_with_rag(ticker)\n",
    "    if not subset:\n",
    "        subset = original_news_list\n",
    "    return analyzer_fn(subset, ticker)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5w714VD3IuRk",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tiny Macro KB\n",
    "import json as _json, os\n",
    "\n",
    "MACRO_KB_DIR = \"kb\"\n",
    "MACRO_KB_PATH = os.path.join(MACRO_KB_DIR, \"macro.json\")\n",
    "os.makedirs(MACRO_KB_DIR, exist_ok=True)\n",
    "\n",
    "if not os.path.exists(MACRO_KB_PATH):\n",
    "    _kb = [\n",
    "        {\"id\":\"cpi_up_bonds_up\",\"title\":\"CPI‚Üë & 10Y‚Üë\",\"text\":\"Rising inflation and yields often pressure rate‚Äësensitive equities; value and financials can sometimes benefit from steeper curves.\"},\n",
    "        {\"id\":\"cpi_down_bonds_down\",\"title\":\"CPI‚Üì & 10Y‚Üì\",\"text\":\"Disinflation with falling yields can support longer‚Äëduration equities; growth names may re‚Äërate upward.\"},\n",
    "        {\"id\":\"unemp_up\",\"title\":\"Unemployment‚Üë\",\"text\":\"Rising unemployment can signal slowing demand; watch consumer discretionary and credit metrics.\"},\n",
    "        {\"id\":\"yc_inversion\",\"title\":\"Yield curve inversion\",\"text\":\"Historically associated with recession risk; defensive positioning and quality balance sheets gain importance.\"}\n",
    "    ]\n",
    "    with open(MACRO_KB_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "        _json.dump(_kb, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "def get_macro_explainer(query: str):\n",
    "    rag = RAGStore(os.path.join(\"kb\", \"macro\"))\n",
    "    try:\n",
    "        with open(MACRO_KB_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "            items = _json.load(f)\n",
    "        rag.upsert(items, text_key=\"text\", id_key=\"id\")\n",
    "    except Exception:\n",
    "        return None\n",
    "    hits = rag.retrieve(query, k=1)\n",
    "    return hits[0][\"text\"] if hits else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0YrnpuTCIuRl",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory RAG for \"what changed since last run\" deltas\n",
    "def upsert_brief_history(ticker: str, brief_text: str, base_dir: str = \"memory\"):\n",
    "    base = os.path.join(base_dir, ticker, \"history_rag\")\n",
    "    rag = RAGStore(base)\n",
    "    doc = {\"id\": f\"{ticker}-{len(rag.docs)}\", \"title\": f\"{ticker} brief\", \"text\": brief_text, \"meta\": {\"ticker\": ticker}}\n",
    "    rag.upsert([doc])\n",
    "\n",
    "def retrieve_prior_brief(ticker: str, base_dir: str = \"memory\"):\n",
    "    base = os.path.join(base_dir, ticker, \"history_rag\")\n",
    "    rag = RAGStore(base)\n",
    "    hits = rag.retrieve(f\"{ticker} investor brief overview risks catalysts\", k=1)\n",
    "    return hits[0][\"text\"] if hits else None\n",
    "\n",
    "def make_delta_paragraph(new_brief: str, prior_brief: str):\n",
    "    if not prior_brief:\n",
    "        return \"\"\n",
    "    new_lines = set([l.strip() for l in new_brief.splitlines() if l.strip()])\n",
    "    old_lines = set([l.strip() for l in prior_brief.splitlines() if l.strip()])\n",
    "    added = list(new_lines - old_lines)[:6]\n",
    "    removed = list(old_lines - new_lines)[:6]\n",
    "    parts = []\n",
    "    if added:\n",
    "        parts.append(\"**New since last brief:** \" + \"; \".join(added))\n",
    "    if removed:\n",
    "        parts.append(\"**No longer emphasized:** \" + \"; \".join(removed))\n",
    "    return \"\\n\".join(parts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "OURnJl2VIuRl",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integration\n",
    "import os\n",
    "\n",
    "def rag_upsert_after_news_fetch(ticker: str, news_list: list, base_dir: str = \"memory\"):\n",
    "    if not news_list:\n",
    "        return 0\n",
    "    rag = RAGStore(os.path.join(base_dir, ticker, \"rag\"))\n",
    "    docs = news_to_rag_docs(news_list, ticker)\n",
    "    return rag.upsert(docs)\n",
    "\n",
    "# Connect to NewsAnalyzer\n",
    "try:\n",
    "    original_fetch_news = NewsAnalyzer.fetch_news\n",
    "    def fetch_news_with_rag(self, ticker: str):\n",
    "        news = original_fetch_news(self, ticker)\n",
    "        try:\n",
    "            rag_upsert_after_news_fetch(ticker, news)\n",
    "        except Exception:\n",
    "            pass\n",
    "        return news\n",
    "    NewsAnalyzer.fetch_news = fetch_news_with_rag\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "#def get_fred_api_key():\n",
    "    #key = os.getenv(\"FRED_API_KEY\")\n",
    "    #if not key:\n",
    "        #raise RuntimeError(\"FRED_API_KEY not set. Please export FRED_API_KEY in your environment.\")\n",
    "    #return key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "goaZSYyhUBqL",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      " INVESTMENT AGENT INTERACTIVE MODE \n",
      "Please enter the requested ticker symbol in the box that appears below each instruction.\n",
      "======================================================================\n",
      "\n",
      "--- 1. Summary Analysis ---\n"
     ]
    }
   ],
   "source": [
    "# INTERACTIVE EXECUTION BLOCK\n",
    "\n",
    "# Initialize the InvestmentResearchAgent\n",
    "agent = InvestmentResearchAgent()\n",
    "\n",
    "# Attach a PromptManager\n",
    "agent.prompt_manager = PromptManager(agent)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" INVESTMENT AGENT INTERACTIVE MODE \")\n",
    "print(\"Please enter the requested ticker symbol in the box that appears below each instruction.\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Interactive Example 1: Summary\n",
    "print(\"\\n--- 1. Summary Analysis ---\")\n",
    "user_ticker_summary = input(\"Enter Ticker for Summary (e.g., AAPL): \").upper()\n",
    "if user_ticker_summary:\n",
    "    print(f\"**TICKER RECEIVED:** {user_ticker_summary}. Running analysis...\")\n",
    "    agent.prompt_manager.execute_prompt(\n",
    "        f\"Provide a comprehensive summary of {user_ticker_summary}'s recent performance including its RSI, key macro trends, and overall news sentiment.\",\n",
    "        ticker=user_ticker_summary\n",
    "    )\n",
    "    time.sleep(1)\n",
    "\n",
    "# Interactive Example 2: Risk Assessment\n",
    "print(\"\\n--- 2. Risk Assessment Analysis ---\")\n",
    "user_ticker_risk = input(\"Enter Ticker for Risk Assessment (e.g., TSLA): \").upper()\n",
    "if user_ticker_risk:\n",
    "    print(f\"**TICKER RECEIVED:** {user_ticker_risk}. Running analysis...\")\n",
    "    agent.prompt_manager.execute_prompt(\n",
    "        f\"Analyze the investment risk for {user_ticker_risk} based on current price trends, relevant macro indicators like CPI, and prevailing news sentiment. Highlight any red flags.\",\n",
    "        ticker=user_ticker_risk\n",
    "    )\n",
    "    time.sleep(1)\n",
    "\n",
    "# Interactive Example 3: Comparison\n",
    "print(\"\\n--- 3. Comparison Analysis ---\")\n",
    "user_ticker1_comp = input(\"Enter FIRST Ticker for Comparison (e.g., AAPL): \").upper()\n",
    "user_ticker2_comp = input(\"Enter SECOND Ticker for Comparison (e.g., MSFT): \").upper()\n",
    "if user_ticker1_comp and user_ticker2_comp:\n",
    "    print(f\"**TICKERS RECEIVED:** {user_ticker1_comp} and {user_ticker2_comp}. Running comparison...\")\n",
    "    agent.prompt_manager.execute_prompt(\n",
    "        f\"Compare {user_ticker1_comp} against {user_ticker2_comp} focusing on their investment performance, recent risks, and how news sentiment differs between them.\",\n",
    "        ticker=user_ticker1_comp,  # Corrected from ticker1 to ticker\n",
    "        ticker2=user_ticker2_comp\n",
    "    )\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" INTERACTIVE MODE ENDED \")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bX899OiV2Mov",
   "metadata": {
    "id": "bX899OiV2Mov"
   },
   "source": [
    "## Code Analysis\n",
    "This is an Investment Research Agent that utilizes agentic AI to coordinate multiple specialized agents to handle complex financial tasks.\n",
    "\n",
    "Data: The code pulls prices/news from yfinance and FRED, computes RSI, basic MA trends, and creates correlation plots.\n",
    "\n",
    "Specialists: There are four agent classes: PriceAnalyzer, MacroAnalyzer, NewsAnalyzer, and NewsSummarizer.\n",
    "\n",
    "Planning and Routing: SynthesisAgent and Prompt Manager orchestrate the run: loading memory --> fetching data --> run specialist agents --> summarize --> generate charts --> persist notes.\n",
    "\n",
    "Self Reflection: The Evaluator Optimizeris found in the Agent Metrics & Reflection section.\n",
    "\n",
    "Learning across runs: load_memory/save_memory persists a per ticker JSON with notes and timestamps.\n",
    "\n",
    "RAG: a local RAGStore is used to build/reuse embedding index for news docs, pre-filter news, and provide context for news briefing for the News Summarizer\n",
    "\n",
    "## Evaluation/Future Improvements\n",
    "Evaluator-Optimizer could be more robust with re-prompting.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_final_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
